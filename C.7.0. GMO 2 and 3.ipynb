{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad362e02",
   "metadata": {},
   "source": [
    "# GMO Forecasting\n",
    "\n",
    "*Case: Grantham, Mayo, and Van Otterloo, 2012: Estimating the Equity Risk Premium\n",
    "[9-211-051].*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a7b04c",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\E}{\\mathbb{E}}\n",
    "\\newcommand{\\cond}{\\, |\\, }\n",
    "\\newcommand{\\var}{\\text{var}}\n",
    "\\newcommand{\\cov}{\\text{cov}}\n",
    "\\newcommand{\\corr}{\\text{corr}}\n",
    "\\newcommand{\\std}{\\text{std}}\n",
    "\\newcommand{\\covmat}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\cdf}{\\Phi}\n",
    "\\newcommand{\\Normal}{\\mathcal{N}}\n",
    "\\newcommand{\\lp}{\\mathbb{L}}\n",
    "\\newcommand{\\dlim}{\\overset{D}{\\to \\;}}\n",
    "\\newcommand{\\plim}{\\overset{P}{\\to \\;}}\n",
    "\\newcommand{\\iid}{i.i.d.}\n",
    "\\newcommand{\\free}{f}\n",
    "\\newcommand{\\ex}[1]{\\tilde{#1}}\n",
    "\\newcommand{\\R}[1][]{R^{#1}}\n",
    "\\newcommand{\\Rf}{\\R[\\free]}\n",
    "\\newcommand{\\Rx}[1][]{\\ex{R}^{#1}}\n",
    "\\renewcommand{\\r}[1][]{r^{\\scriptscriptstyle {#1}}}\n",
    "\\newcommand{\\rf}{\\r[\\free]}\n",
    "\\newcommand{\\rx}[1][]{\\ex{r}^{\\scriptscriptstyle {#1}}}\n",
    "\\newcommand{\\rlog}[1][]{{\\texttt{r}^{#1}}}\n",
    "\\newcommand{\\rflog}{\\rlog[\\free]}\n",
    "\\newcommand{\\rvec}[1][]{\\boldsymbol{\\r[#1]}}\n",
    "\\newcommand{\\rxvec}[1][]{\\boldsymbol{\\rx[#1]}}\n",
    "\\newcommand{\\pay}[1][]{\\Gamma^{\\scriptscriptstyle {#1}}}\n",
    "\\renewcommand{\\P}{\\mathcal{P}}\n",
    "\\newcommand{\\ind}[1]{_{[#1]}}\n",
    "\\newcommand{\\notind}[1]{\\ind{-#1}}\n",
    "\\newcommand{\\coord}{\\boldsymbol{\\iota}}\n",
    "\\newcommand{\\obs}{n}\n",
    "\\newcommand{\\Nobs}{N}\n",
    "\\newcommand{\\lag}{h}\n",
    "\\newcommand{\\Nlag}{H}\n",
    "\\newcommand{\\indx}{i}\n",
    "\\newcommand{\\indxalt}{j}\n",
    "\\newcommand{\\I}{\\mathcal{I}}\n",
    "\\newcommand{\\one}{\\textbf{1}}\n",
    "\\newcommand{\\zeros}{\\textbf{0}}\n",
    "\\newcommand{\\x}{\\textbf{x}}\n",
    "\\newcommand{\\z}{\\textbf{z}}\n",
    "\\newcommand{\\y}{\\textbf{y}}\n",
    "\\newcommand{\\w}{\\textbf{w}}\n",
    "\\newcommand{\\X}{\\textbf{X}}\n",
    "\\newcommand{\\Z}{\\textbf{Z}}\n",
    "\\newcommand{\\Y}{\\textbf{Y}}\n",
    "\\newcommand{\\W}{\\textbf{W}}\n",
    "\\newcommand{\\alphavec}{\\boldsymbol{\\alpha}}\n",
    "\\newcommand{\\betavec}{\\boldsymbol{\\beta}}\n",
    "\\newcommand{\\epsilonvec}{\\boldsymbol{\\epsilon}}\n",
    "\\newcommand{\\sigmavec}{\\boldsymbol{\\sigma}}\n",
    "\\newcommand{\\mux}{\\ex{\\mu}}\n",
    "\\newcommand{\\muvec}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\muxvec}{\\boldsymbol{\\ex{\\mu}}}\n",
    "\\newcommand{\\muP}{\\mu^p}\n",
    "\\newcommand{\\Sigmamat}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\wt}{\\boldsymbol{\\omega}}\n",
    "\\newcommand{\\wtx}{\\boldsymbol{w}}\n",
    "\\newcommand{\\wtxstar}{\\wtx^*}\n",
    "\\newcommand{\\wtTan}{\\wt^{\\tan}}\n",
    "\\newcommand{\\wtxTan}{\\wtx^{\\tan}}\n",
    "\\newcommand{\\wtGMV}{\\wt^{\\gmv}}\n",
    "\\newcommand{\\mv}{\\scriptscriptstyle {\\subset}}\n",
    "\\newcommand{\\MV}{$\\ex{\\text{MV}}\\ $}\n",
    "\\newcommand{\\MVscale}{\\delta}\n",
    "\\newcommand{\\ifac}{k}\n",
    "\\newcommand{\\Nfacs}{k}\n",
    "\\newcommand{\\fbeta}[1][]{\\beta^{\\scriptscriptstyle {#1}}}\n",
    "\\newcommand{\\fbetavec}[1][]{\\betavec^{\\scriptscriptstyle {#1}}}\n",
    "\\newcommand{\\radon}{q}\n",
    "\\newcommand{\\mkt}{m}\n",
    "\\newcommand{\\act}{a}\n",
    "\\renewcommand{\\tan}{\\texttt{t}}\n",
    "\\newcommand{\\gmv}{\\texttt{v}}\n",
    "\\newcommand{\\size}{s}\n",
    "\\newcommand{\\val}{v}\n",
    "\\newcommand{\\up}{u}\n",
    "\\newcommand{\\mom}{\\text{mom}}\n",
    "\\newcommand{\\orthog}{\\alpha}\n",
    "\\newcommand{\\fac}{z}\n",
    "\\newcommand{\\facs}{\\boldsymbol{z}}\n",
    "\\newcommand{\\facmac}{f}\n",
    "\\newcommand{\\facsmac}{\\boldsymbol{f}}\n",
    "\\newcommand{\\prem}{\\lambda}\n",
    "\\newcommand{\\premvec}{\\boldsymbol{\\prem}}\n",
    "\\newcommand{\\pos}{i}\n",
    "\\newcommand{\\hedge}{j}\n",
    "\\newcommand{\\etavec}{\\boldsymbol{\\eta}}\n",
    "\\newcommand{\\Q}{\\textbf{Q}}\n",
    "\\newcommand{\\eig}{\\psi}\n",
    "\\newcommand{\\Eig}{\\Psi}\n",
    "\\newcommand{\\eigv}{\\textbf{q}}\n",
    "\\newcommand{\\Eigv}{Q}\n",
    "\\newcommand{\\PCwt}{\\textbf{q}}\n",
    "\\newcommand{\\PCfac}{x}\n",
    "\\newcommand{\\VaR}{\\text{VaR}}\n",
    "\\newcommand{\\ES}{\\text{ES}}\n",
    "\\newcommand{\\Rrate}{\\,\\r}\n",
    "\\newcommand{\\Rratevec}{\\,\\rvec}\n",
    "\\newcommand{\\RVaR}{\\, \\r[\\text{VaR}]}\n",
    "\\newcommand{\\RES}{\\,\\r[\\text{ES}]}\n",
    "\\newcommand{\\rVaR}{\\, \\r[\\text{VaR}]}\n",
    "\\newcommand{\\rES}{\\, \\r[\\text{ES}]}\n",
    "\\newcommand{\\thresh}{\\pi}\n",
    "\\newcommand{\\quantile}{\\texttt{z}_{\\thresh}}\n",
    "\\newcommand{\\gain}{\\Delta V}\n",
    "\\newcommand{\\loss}{L}\n",
    "\\newcommand{\\lossvec}{\\textbf{L}}\n",
    "\\newcommand{\\cdfnorm}{\\Phi}\n",
    "\\newcommand{\\cdflosst}{F^\\ell_\\tau}\n",
    "\\newcommand{\\cdfgaint}{F^g_\\tau}\n",
    "\\newcommand{\\cdfretst}{F^{\\r}_\\tau}\n",
    "\\newcommand{\\invcdflosst}{F_\\tau^{\\ell(-1)}}\n",
    "\\newcommand{\\invcdfgaint}{F_\\tau^{g[-1]}}\n",
    "\\newcommand{\\invcdfretst}{F^{\\r(-1)}_\\tau}\n",
    "\\newcommand{\\mawt}{\\theta}\n",
    "\\newcommand{\\DP}{\\text{DP}}\n",
    "\\newcommand{\\n}{{(n)}}\n",
    "\\newcommand{\\0}{(0)}\n",
    "\\newcommand{\\1}{{(1)}}\n",
    "\\newcommand{\\2}{{(2)}}\n",
    "\\newcommand{\\3}{{(3)}}\n",
    "\\newcommand{\\4}{{(4)}}\n",
    "\\newcommand{\\5}{{(5)}}\n",
    "\\newcommand{\\bonds}{B}\n",
    "\\newcommand{\\fx}{S}\n",
    "\\newcommand{\\fxlog}{\\texttt{s}}\n",
    "\\newcommand{\\meuro}{\\text{\\euro}}\n",
    "\\newcommand{\\usd}{\\$}\n",
    "\\newcommand{\\for}{F}\n",
    "\\newcommand{\\forlog}{\\texttt{f}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07313a8c",
   "metadata": {},
   "source": [
    "## 1 READING: GMO\n",
    "\n",
    "This section is not graded, and you do not need to submit your answers. But you are expected to consider these issues and be ready to discuss them.\n",
    "\n",
    "1. **GMO’s approach.**\n",
    "   - Why does GMO believe they can more easily predict **long‑run** than **short‑run** asset‑class performance?\n",
    "   - What predicting variables does the case mention are used by GMO? Does this fit with the goal of long‑run forecasts?\n",
    "   - How has this approach led to **contrarian** positions?\n",
    "   - How does this approach raise **business risk** and **managerial career risk**?\n",
    "\n",
    "2. **The market environment.**\n",
    "   - We often estimate the market risk premium by looking at a large sample of historic data. What reasons does the case give to be skeptical that the market risk premium will be as high **in the future** as it has been **over the past 50 years**?\n",
    "   - In 2007, GMO forecasts **real excess equity returns** will be negative. What are the biggest drivers of their **pessimistic conditional** forecast relative to the **unconditional** forecast? (See Exhibit 9.)\n",
    "   - In the 2011 forecast, what components has GMO revised most relative to 2007? Now how does their conditional forecast compare to the unconditional? (See Exhibit 10.)\n",
    "\n",
    "3. **Consider the asset‑class forecasts in Exhibit 1.**\n",
    "   - Which asset class did GMO estimate to have a **negative 10‑year return** over 2002–2011?\n",
    "   - Which asset classes substantially **outperformed** GMO’s estimate over that time period?\n",
    "   - Which asset classes substantially **underperformed** GMO’s estimate over that time period?\n",
    "\n",
    "4. **Fund performance.**\n",
    "   - In which asset class was **GMWAX** most heavily allocated throughout the majority of 1997–2011?\n",
    "   - Comment on the performance of GMWAX versus its benchmark. (No calculation needed; simply comment on the comparison in the exhibits.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56c71be",
   "metadata": {},
   "source": [
    "## 2 Analyzing GMO\n",
    "\n",
    "_This section utilizes data in the file `gmo_data.xlsx`._ Convert total returns to **excess returns** using the risk‑free rate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2618685",
   "metadata": {},
   "source": [
    "1. **Performance (GMWAX).** Compute **mean**, **volatility**, and **Sharpe ratio** for **GMWAX** over three samples:\n",
    "   - inception → 2011\n",
    "   - 2012 → present\n",
    "   - inception → present  \n",
    "   Has the mean, vol, and Sharpe changed much since the case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550054ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy statsmodels matplotlib seaborn scipy openpyxl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "rets = pd.read_excel('gmo_analysis_data.xlsx',\n",
    "                     sheet_name='total returns',\n",
    "                     index_col='date')\n",
    "\n",
    "rfr = pd.read_excel('gmo_analysis_data.xlsx',\n",
    "                    sheet_name='risk-free rate',\n",
    "                    index_col='date') / 12\n",
    "\n",
    "retsx = rets.subtract(rfr['TBill 3M'], axis=0)\n",
    "\n",
    "def performance(sample):\n",
    "    mu = sample.mean() * 12\n",
    "    vol = sample.std() * np.sqrt(12)\n",
    "    sharpe = mu / vol\n",
    "    return pd.DataFrame({'Mean': mu, 'Vol': vol, 'Sharpe': sharpe})\n",
    "\n",
    "samples_perf = {\n",
    "    '1996-2011': retsx.loc[:'2011-12-31'],\n",
    "    '2012-2025': retsx.loc['2012-01-01':],\n",
    "    '1996-2025': retsx\n",
    "}\n",
    "\n",
    "res_perf = {k: performance(v) for k, v in samples_perf.items()}\n",
    "pd.concat(res_perf, names=['Sample', 'Asset']).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa735390",
   "metadata": {},
   "source": [
    "2. **Tail risk (GMWAX).** For all three samples, analyze extreme scenarios:\n",
    "   - minimum return\n",
    "   - 5th percentile (VaR‑5th)\n",
    "   - maximum drawdown (compute on **total** returns, not excess returns)  \n",
    "   (a) Does GMWAX have high or low tail‑risk as seen by these stats?  \n",
    "   (b) Does that vary much across the two subsamples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1f6f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tailrisk(sample):\n",
    "    min_ret = sample.min()\n",
    "    var5 = sample.quantile(0.05)\n",
    "    dd = sample.apply(lambda x: (1+x).cumprod().div((1+x).cumprod().cummax()).sub(1))\n",
    "    return pd.DataFrame({'Min Return': min_ret, 'VaR (5%)': var5, 'Max Drawdown': dd.min()})\n",
    "\n",
    "samples_tail = {\n",
    "    '1996-2011': rets.loc[:'2011-12-31'],\n",
    "    '2012-2025': rets.loc['2012-01-01':],\n",
    "    '1996-2025': rets\n",
    "}\n",
    "\n",
    "res_tail = {k: tailrisk(v) for k, v in samples_tail.items()}\n",
    "pd.concat(res_tail, names=['Sample', 'Asset']).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e27b1fa",
   "metadata": {},
   "source": [
    "3. **Market exposure (GMWAX).** For all three samples, regress **excess returns of GMWAX** on **excess returns of SPY**:\n",
    "   - report estimated **alpha**, **beta**, and **R²**\n",
    "   - is GMWAX a **low‑beta** strategy? has that changed since the case?\n",
    "   - does GMWAX provide **alpha**? has that changed across subsamples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37709ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg(sample):\n",
    "    rows = []\n",
    "    for asset in ['GMWAX', 'GMGEX']:\n",
    "        y = sample[asset]                 # excess returns of fund\n",
    "        X = sm.add_constant(sample['SPY']) # excess returns of SPY\n",
    "        m = sm.OLS(y, X, missing='drop').fit()\n",
    "        rows.append([asset, m.params['const'], m.params['SPY'], m.rsquared])\n",
    "    return pd.DataFrame(rows, columns=['Asset','alpha','beta','R2']).set_index('Asset')\n",
    "\n",
    "# Use retsx (excess returns), not xr\n",
    "samples_reg = {\n",
    "    '1996-2011': retsx.loc[:'2011-12-31'],\n",
    "    '2012-2025': retsx.loc['2012-01-01':],\n",
    "    '1996-2025': retsx\n",
    "}\n",
    "\n",
    "res_reg = {k: reg(v) for k, v in samples_reg.items()}\n",
    "pd.concat(res_reg, names=['Sample','Asset']).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5303bed7",
   "metadata": {},
   "source": [
    "Is GMWAX/GMGEX a low-beta strategy? Has that changed?\n",
    "GMWAX\n",
    "Betas across samples:\n",
    "\n",
    "0.6195 (1996–2011)\n",
    "0.6294 (2012–2025)\n",
    "0.6224 (full sample)\n",
    "These are all well below 1, so GMWAX is consistently a low-beta strategy. Beta has been very stable with no meaningful change since the case.\n",
    "\n",
    "GMGEX\n",
    "Betas across samples:\n",
    "\n",
    "0.8147 (1996–2011)\n",
    "0.8042 (2012–2025)\n",
    "0.8040 (full sample)\n",
    "These are also below 1, so GMGEX is technically \"low-beta,\" though much closer to 1. Beta is again very stable, showing little change over time.\n",
    "\n",
    "Does GMWAX/GMGEX provide alpha? Has that changed?\n",
    "GMWAX\n",
    "Alphas:\n",
    "\n",
    "–0.0079 (1996–2011)\n",
    "–0.0083 (2012–2025)\n",
    "–0.0081 (full sample)\n",
    "All alphas are negative and very similar. GMWAX does not generate excess return beyond what its beta predicts, and its alpha has not changed significantly across subsamples.\n",
    "\n",
    "GMGEX\n",
    "Alphas:\n",
    "\n",
    "–0.0076 (1996–2011)\n",
    "–0.0108 (2012–2025)\n",
    "–0.0092 (full sample)\n",
    "GMGEX's alpha is also consistently negative, but unlike GMWAX, it becomes more negative in the 2012–2025 period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72f8950",
   "metadata": {},
   "source": [
    "4. **Compare to GMGEX.** Repeat items 1–3 for **GMGEX**. What are key differences between the two strategies?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d9a6de",
   "metadata": {},
   "source": [
    "1. Risk & Return\n",
    "GMWAX: Lower volatility, lower tail-risk, and more stable Sharpe ratio.\n",
    "GMGEX: Higher volatility, much deeper drawdowns, and weaker/unstable Sharpe ratio.\n",
    "GMWAX is the more defensive fund; GMGEX is the more aggressive/global-risk fund.\n",
    "\n",
    "2. Market Exposure\n",
    "GMWAX: Lower beta (~0.62), high R² → behaves like a steady, defensive value fund.\n",
    "GMGEX: Higher beta (~0.80), lower R² → more idiosyncratic risks, currency effects, country shocks.\n",
    "3. Alpha and Return Drivers\n",
    "Neither fund produces positive alpha.\n",
    "\n",
    "GMWAX: Alpha is consistently negative but stable.\n",
    "GMGEX: Alpha becomes more negative in recent sample.\n",
    "This suggests GMWAX is more predictable and factor-driven, while GMGEX is more sensitive to global cycles and suffers more in risk-off years."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5207eb",
   "metadata": {},
   "source": [
    "## 3 Forecast Regressions\n",
    "\n",
    "_This section utilizes data in `gmo_data.xlsx`._\n",
    "\n",
    "1. **Lagged regression.** Consider the regression with predictors lagged one period:\n",
    "\n",
    "$$\n",
    "r^{SPY}_{t} \\;=\\; \\alpha^{SPY,X} \\;+\\; \\big(\\beta^{SPY,X}\\big)^\\prime X_{t-1} \\;+\\; \\epsilon^{SPY,X}_{t}\n",
    "\\tag{1}\n",
    "$$\n",
    "\n",
    "Estimate (1) and report the **$R^2$**, as well as the OLS estimates for $\\alpha$ and $\\beta$. Do this for:\n",
    "   - $X$ as a single regressor, the **dividend–price** ratio ($DP$)\n",
    "   - $X$ as a single regressor, the **earnings–price** ratio ($EP$)\n",
    "   - $X$ with **three** regressors: $DP$, $EP$, and the **10‑year yield**  \n",
    "   For each, report the **$R^2$**.\n",
    "\n",
    "2. **Trading strategy from forecasts.** For each of the three regressions:\n",
    "   - Build the forecasted SPY return: $\\hat r^{SPY}_{t+1}$ (forecast made using $X_t$ to predict $r^{SPY}_{t+1}$).\n",
    "   - Set the scale (portfolio weight) to $w_t = 100 \\,\\hat r^{SPY}_{t+1}$.\n",
    "   - Strategy return: $r^x_{t+1} = w_t\\, r^{SPY}_{t+1}$.  \n",
    "   For each strategy, compute:\n",
    "   - mean, volatility, Sharpe\n",
    "   - max drawdown\n",
    "   - market **alpha**\n",
    "   - market **beta**\n",
    "   - market **information ratio**\n",
    "\n",
    "3. **Risk characteristics.**\n",
    "   - For both strategies, the market, and GMO, compute monthly **VaR** at $\\pi = 0.05$ (use the historical quantile).\n",
    "   - The case mentions stocks under‑performed short‑term bonds from 2000–2011. Does the dynamic portfolio above under‑perform the risk‑free rate over this time?\n",
    "   - Based on the regression estimates, in how many periods do we estimate a **negative risk premium**?\n",
    "   - Do you believe the dynamic strategy takes on **extra risk**?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf31933",
   "metadata": {},
   "source": [
    "3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f0dcbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DP only regression ===\n",
      "R^2: 0.007262714234388512\n",
      "OLS estimates (α and β):\n",
      "const          -0.007793\n",
      "SPX D/P_lag1    0.928617\n",
      "dtype: float64\n",
      "\n",
      "=== EP only regression ===\n",
      "R^2: 0.004827277817505693\n",
      "OLS estimates (α and β):\n",
      "const          -0.004074\n",
      "SPX E/P_lag1    0.240449\n",
      "dtype: float64\n",
      "\n",
      "=== DP + EP + 10Y regression ===\n",
      "R^2: 0.008637555438353206\n",
      "OLS estimates (α and β):\n",
      "const              -0.002655\n",
      "SPX D/P_lag1        0.445540\n",
      "SPX E/P_lag1        0.142754\n",
      "T-Note 10YR_lag1   -0.117296\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "file = \"gmo_analysis_data.xlsx\"         \n",
    "\n",
    "signals = pd.read_excel(file, sheet_name=\"signals\")       \n",
    "returns = pd.read_excel(file, sheet_name=\"total returns\") \n",
    "\n",
    "\n",
    "data = pd.merge(\n",
    "    returns[[\"date\", \"SPY\"]],\n",
    "    signals,\n",
    "    on=\"date\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "\n",
    "pred_cols = [\"SPX D/P\", \"SPX E/P\", \"T-Note 10YR\"]\n",
    "\n",
    "for col in pred_cols:\n",
    "    data[col + \"_lag1\"] = data[col].shift(1)\n",
    "\n",
    "\n",
    "data = data.dropna().reset_index(drop=True)\n",
    "\n",
    "\n",
    "y = data[\"SPY\"]\n",
    "\n",
    "\n",
    "regressor_sets = {\n",
    "    \"DP only\" : [\"SPX D/P_lag1\"],\n",
    "    \"EP only\" : [\"SPX E/P_lag1\"],\n",
    "    \"DP + EP + 10Y\" : [\"SPX D/P_lag1\", \"SPX E/P_lag1\", \"T-Note 10YR_lag1\"],\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, cols in regressor_sets.items():\n",
    "    X = sm.add_constant(data[cols])      \n",
    "    model = sm.OLS(y, X).fit()\n",
    "    results[name] = model\n",
    "\n",
    "    print(f\"=== {name} regression ===\")\n",
    "    print(\"R^2:\", model.rsquared)\n",
    "    print(\"OLS estimates (α and β):\")\n",
    "    print(model.params)\n",
    "    print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da3c9f8",
   "metadata": {},
   "source": [
    "3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e73c6bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DP regression ===\n",
      "R^2: 0.007262714234388512\n",
      "α and β estimates:\n",
      "const          -0.007793\n",
      "SPX D/P_lag1    0.928617\n",
      "dtype: float64\n",
      "\n",
      "=== EP regression ===\n",
      "R^2: 0.004827277817505693\n",
      "α and β estimates:\n",
      "const          -0.004074\n",
      "SPX E/P_lag1    0.240449\n",
      "dtype: float64\n",
      "\n",
      "=== DP_EP_10Y regression ===\n",
      "R^2: 0.008637555438353206\n",
      "α and β estimates:\n",
      "const              -0.002655\n",
      "SPX D/P_lag1        0.445540\n",
      "SPX E/P_lag1        0.142754\n",
      "T-Note 10YR_lag1   -0.117296\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "===== DP strategy stats =====\n",
      "mean_monthly   : 0.009252\n",
      "vol_monthly    : 0.046671\n",
      "sharpe_ann     : 0.548752\n",
      "max_drawdown   : -0.665395\n",
      "alpha_month    : 0.000972\n",
      "alpha_ann      : 0.011668\n",
      "beta           : 0.934073\n",
      "info_ratio_ann : 0.081512\n",
      "\n",
      "===== EP strategy stats =====\n",
      "mean_monthly   : 0.008495\n",
      "vol_monthly    : 0.043182\n",
      "sharpe_ann     : 0.533274\n",
      "max_drawdown   : -0.593091\n",
      "alpha_month    : 0.000358\n",
      "alpha_ann      : 0.004299\n",
      "beta           : 0.913308\n",
      "info_ratio_ann : -0.052873\n",
      "\n",
      "===== DP_EP_10Y strategy stats =====\n",
      "mean_monthly   : 0.009409\n",
      "vol_monthly    : 0.046135\n",
      "sharpe_ann     : 0.566540\n",
      "max_drawdown   : -0.637631\n",
      "alpha_month    : 0.001210\n",
      "alpha_ann      : 0.014525\n",
      "beta           : 0.922324\n",
      "info_ratio_ann : 0.106357\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "file = \"gmo_analysis_data.xlsx\"   \n",
    "\n",
    "signals = pd.read_excel(file, sheet_name=\"signals\")\n",
    "returns = pd.read_excel(file, sheet_name=\"total returns\")\n",
    "rf      = pd.read_excel(file, sheet_name=\"risk-free rate\")\n",
    "\n",
    "\n",
    "df = (signals\n",
    "      .merge(returns, on=\"date\")\n",
    "      .merge(rf,      on=\"date\"))\n",
    "\n",
    "\n",
    "df[\"rf_month\"] = df[\"TBill 3M\"] / 12.0\n",
    "\n",
    "\n",
    "signal_cols = [\"SPX D/P\", \"SPX E/P\", \"T-Note 10YR\"]\n",
    "\n",
    "for col in signal_cols:\n",
    "    df[col + \"_lag1\"] = df[col].shift(1)\n",
    "\n",
    "\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "\n",
    "regressor_sets = {\n",
    "    \"DP\"         : [\"SPX D/P_lag1\"],\n",
    "    \"EP\"         : [\"SPX E/P_lag1\"],\n",
    "    \"DP_EP_10Y\"  : [\"SPX D/P_lag1\", \"SPX E/P_lag1\", \"T-Note 10YR_lag1\"],\n",
    "}\n",
    "\n",
    "models = {}\n",
    "\n",
    "for name, cols in regressor_sets.items():\n",
    "    X = sm.add_constant(df[cols])\n",
    "    y = df[\"SPY\"]\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    models[name] = model\n",
    "\n",
    "    print(f\"=== {name} regression ===\")\n",
    "    print(\"R^2:\", model.rsquared)\n",
    "    print(\"α and β estimates:\")\n",
    "    print(model.params)\n",
    "    print()\n",
    "\n",
    "\n",
    "def build_strategy_returns(df, model, strat_name):\n",
    " \n",
    "    df[f\"forecast_{strat_name}\"] = model.fittedvalues\n",
    "\n",
    "    \n",
    "    w = 100.0 * df[f\"forecast_{strat_name}\"]\n",
    "\n",
    "    \n",
    "    strat_ret = w.shift(1) * df[\"SPY\"]   \n",
    "\n",
    "    return strat_ret\n",
    "\n",
    "strategies = {}\n",
    "for name, model in models.items():\n",
    "    strategies[name] = build_strategy_returns(df, model, name)\n",
    "\n",
    "\n",
    "def strategy_stats(df, strat_returns):\n",
    "\n",
    "    data = pd.DataFrame({\n",
    "        \"strategy\": strat_returns,\n",
    "        \"SPY\": df[\"SPY\"],\n",
    "        \"rf\": df[\"rf_month\"],\n",
    "    }).dropna()\n",
    "\n",
    "    r_s = data[\"strategy\"]\n",
    "    r_m = data[\"SPY\"]\n",
    "    r_f = data[\"rf\"]\n",
    "\n",
    "   \n",
    "    excess_s = r_s - r_f\n",
    "    excess_m = r_m - r_f\n",
    "\n",
    "    \n",
    "    mean_ret = r_s.mean()\n",
    "    vol_ret  = r_s.std(ddof=1)\n",
    "\n",
    "    \n",
    "    sharpe_ann = (excess_s.mean() / excess_s.std(ddof=1)) * np.sqrt(12)\n",
    "\n",
    "   \n",
    "    cum = (1 + r_s).cumprod()\n",
    "    running_max = cum.cummax()\n",
    "    drawdown = cum / running_max - 1.0\n",
    "    max_dd = drawdown.min()\n",
    "\n",
    "    \n",
    "    X = sm.add_constant(excess_m)\n",
    "    reg = sm.OLS(excess_s, X).fit()\n",
    "    alpha_month = reg.params.iloc[0]\n",
    "    beta        = reg.params.iloc[1]\n",
    "    alpha_ann   = alpha_month * 12.0  \n",
    "\n",
    "    \n",
    "    active = excess_s - excess_m        \n",
    "    info_ratio_ann = (active.mean() / active.std(ddof=1)) * np.sqrt(12)\n",
    "\n",
    "    return {\n",
    "        \"mean_monthly\": mean_ret,\n",
    "        \"vol_monthly\": vol_ret,\n",
    "        \"sharpe_ann\": sharpe_ann,\n",
    "        \"max_drawdown\": max_dd,\n",
    "        \"alpha_month\": alpha_month,\n",
    "        \"alpha_ann\": alpha_ann,\n",
    "        \"beta\": beta,\n",
    "        \"info_ratio_ann\": info_ratio_ann,\n",
    "    }\n",
    "\n",
    "\n",
    "for name, strat in strategies.items():\n",
    "    print(f\"\\n===== {name} strategy stats =====\")\n",
    "    stats = strategy_stats(df, strat)\n",
    "    for k, v in stats.items():\n",
    "        print(f\"{k:15s}: {v:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685190cc",
   "metadata": {},
   "source": [
    "3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e38b27da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP VaR (5%): -0.061514\n",
      "EP VaR (5%): -0.064603\n",
      "DP_EP_10Y VaR (5%): -0.063971\n",
      "Market VaR (5%): -0.07442817951315703\n",
      "GMO VaR (5%): -0.04038561221646227\n"
     ]
    }
   ],
   "source": [
    "def compute_var_5(ret):\n",
    "    return np.quantile(ret.dropna(), 0.05)\n",
    "\n",
    "\n",
    "for name, strat in strategies.items():\n",
    "    print(f\"{name} VaR (5%): {compute_var_5(strat):.6f}\")\n",
    "\n",
    "\n",
    "market_var = compute_var_5(df[\"SPY\"])\n",
    "print(\"Market VaR (5%):\", market_var)\n",
    "\n",
    "\n",
    "gmo_var = compute_var_5(df[\"GMWAX\"])\n",
    "print(\"GMO VaR (5%):\", gmo_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1abef1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP mean excess return (2000–2011): 0.0028978799242101927\n",
      "EP mean excess return (2000–2011): 0.0014695121084539583\n",
      "DP_EP_10Y mean excess return (2000–2011): 0.0029109510731997767\n"
     ]
    }
   ],
   "source": [
    "period = df[(df[\"date\"] >= \"2000-01-01\") & (df[\"date\"] <= \"2011-12-31\")]\n",
    "\n",
    "for name, strat in strategies.items():\n",
    "    sub = strat.loc[period.index]\n",
    "    excess = sub - period[\"rf_month\"]\n",
    "\n",
    "    print(name, \"mean excess return (2000–2011):\", excess.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814e260e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The case mentioned that US eqs underperformed the short term bonds from 2000-2011 by .1% but upon evaluation of the three forecasting strategies done over the same windows, they all produced positive excess returns relative to the 3 month t-bill rate (as shown above). Thus, the dynamic portfolio did not underperform the rf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f2a3d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP: 25 negative risk-premium months out of 346\n",
      "EP: 1 negative risk-premium months out of 346\n",
      "DP_EP_10Y: 44 negative risk-premium months out of 346\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "neg_counts = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "   \n",
    "    cols = [c for c in model.model.exog_names if c != \"const\"]\n",
    "\n",
    "    X = sm.add_constant(df[cols])\n",
    "\n",
    "    r_hat = model.predict(X)\n",
    "\n",
    "    rp_hat = r_hat - df[\"rf_month\"]\n",
    "\n",
    "    neg = (rp_hat < 0).sum()\n",
    "    total = rp_hat.notna().sum()\n",
    "\n",
    "    neg_counts[name] = (neg, total)\n",
    "    print(f\"{name}: {neg} negative risk-premium months out of {total}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510d5234",
   "metadata": {},
   "source": [
    "Yes the dynamic strategy does take on extra risk \n",
    "\n",
    "since the portoflio weight is proportional to the next-period forecasted return, the strategy calculates large long or short positions based on the regression producing extreme signals, and forecasts are noisy so the resulting exposures that are produced are unstable ones -- and this yields higher ret. vol, and quite high downside tail risks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840dba57",
   "metadata": {},
   "source": [
    "## 4 Out‑of‑Sample Forecasting\n",
    "\n",
    "_This section utilizes data in `gmo_data.xlsx`._ Focus on using **both** $DP$ and $EP$ as signals in (1). Compute **out‑of‑sample** ($OOS$) statistics:\n",
    "\n",
    "**Procedure (rolling OOS):**\n",
    "- Start at $t=60$.\n",
    "- Estimate (1) using data **through** time $t$.\n",
    "- Using the estimated parameters and $x_t$, compute the forecast for $t+1$:\n",
    "  \n",
    "  $$\n",
    "  \\hat r^{SPY}_{t+1} \\;=\\; \\hat \\alpha^{SPY,X}_t \\;+\\; \\big(\\hat \\beta^{SPY,X}_t\\big)^\\prime x_t\n",
    "  $$\n",
    "\n",
    "- Forecast error: $e^{forecast}_{t+1} = r^{SPY}_{t+1} - \\hat r^{SPY}_{t+1}$.\n",
    "- Move to $t=61$ and iterate.\n",
    "\n",
    "Also compute the **null** forecast and errors:\n",
    "\n",
    "$$\n",
    "\\bar r^{SPY}_{t+1} = \\frac{1}{t}\\sum_{i=1}^t r^{SPY}_i, \\qquad\n",
    "e^{null}_{t+1} = r^{SPY}_{t+1} - \\bar r^{SPY}_{t+1}.\n",
    "$$\n",
    "\n",
    "1. **Report the out‑of‑sample $R^2$**\n",
    "\n",
    "$$\n",
    "R^2_{OOS} \\;\\equiv\\; 1 - \\frac{\\sum_{i=61}^T \\big(e^{forecast}_i\\big)^2}{\\sum_{i=61}^T \\big(e^{null}_i\\big)^2}\n",
    "$$\n",
    "\n",
    "Did this forecasting strategy produce a positive $R^2_{OOS}$?\n",
    "\n",
    "2. **Redo 3.2 with OOS forecasts.** How does the OOS strategy compare to the in‑sample version of 3.2?\n",
    "\n",
    "3. **Redo 3.3 with OOS forecasts.** Is the point‑in‑time version of the strategy **riskier**?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007e75ed",
   "metadata": {},
   "source": [
    "## 5 EXTRA: ML Forecasts\n",
    "\n",
    "1. **CART.** Re‑do Section 3 using **CART** (e.g., `RandomForestRegressor` from `sklearn.ensemble`). If you want to visualize, try `sklearn.tree`.\n",
    "2. **CART, OOS.** Compute out‑of‑sample stats as in Section 4.\n",
    "3. **Neural Network.** Re‑do Section 3 using a **neural network** (e.g., `MLPRegressor` from `sklearn.neural_network`).\n",
    "4. **NN & CART, OOS.** Compute out‑of‑sample stats as in Section 4."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "cc02d3ae52bb91c8a1b5ad0464ab536a3b26987b7fb4cfff4c5c78c741c5c26e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
